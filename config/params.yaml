model:
  architecture:
    hidden_layers: [64, 32, 16]
    dropout_rate: 0.4
    use_batch_norm: true
    use_attention: true
    activation: "relu"
    output_activation: "sigmoid"

  training:
    optimizer: "adam"
    learning_rate: 0.001
    loss: "binary_crossentropy"
    metrics: ["accuracy", "precision", "recall", "auc"]
    batch_size: 32
    epochs: 200

  callbacks:
    early_stopping:
      monitor: "val_auc"
      patience: 20
      mode: "max"
      restore_best_weights: true

    reduce_lr:
      monitor: "val_loss"
      factor: 0.5
      patience: 10
      min_lr: 0.00001

    checkpoint:
      filepath: "data/models/best_model.h5"
      save_best_only: true
      monitor: "val_auc"